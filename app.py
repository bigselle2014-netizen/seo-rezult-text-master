import os
import re
import requests
import numpy as np
import streamlit as st
from datetime import datetime
from urllib.parse import quote
from docx import Document
from supabase import create_client, Client
from keep_alive import keep_alive

# =========================
# üîê –ö–õ–Æ–ß–ò –ò –ö–õ–ò–ï–ù–¢–´ (ENV)
# =========================
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")
PPLX_API_KEY = os.environ.get("PPLX_API_KEY")
TEXT_RU_KEY  = os.environ.get("TEXT_RU_KEY")

missing = [k for k, v in {
    "SUPABASE_URL": SUPABASE_URL,
    "SUPABASE_KEY": SUPABASE_KEY,
    "PPLX_API_KEY": PPLX_API_KEY,
    "TEXT_RU_KEY": TEXT_RU_KEY,
}.items() if not v]
if missing:
    st.error("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω—ã –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: " + ", ".join(missing))
    st.stop()

supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# =========================
# ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ò UI
# =========================
st.set_page_config(page_title="SEO Rezult Text Master v7.4", layout="wide")

# =========================
# üë§ –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø (SIDEBAR)
# =========================
if "user" not in st.session_state:
    st.session_state.user = None

with st.sidebar:
    st.header("üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è")

    if st.session_state.user:
        st.success(f"–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, {st.session_state.user['email']}!")
        if st.button("–í—ã–π—Ç–∏"):
            st.session_state.user = None
            st.rerun()
    else:
        mode = st.radio("–î–µ–π—Å—Ç–≤–∏–µ", ["–í—Ö–æ–¥", "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è"], horizontal=True)
        email = st.text_input("Email")
        password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")
        if st.button("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å"):
            try:
                if mode == "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è":
                    if email.strip().lower() == "admin@seo-rezult.ru":
                        st.error("–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–¥ —ç—Ç–∏–º –∞–¥—Ä–µ—Å–æ–º –∑–∞–ø—Ä–µ—â–µ–Ω–∞.")
                    else:
                        res = supabase.auth.sign_up({"email": email, "password": password})
                        if getattr(res, "user", None):
                            st.success("‚úÖ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —É—Å–ø–µ—à–Ω–∞. –¢–µ–ø–µ—Ä—å –≤–æ–π–¥–∏—Ç–µ.")
                        else:
                            st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ email/–ø–∞—Ä–æ–ª—å.")
                else:
                    res = supabase.auth.sign_in_with_password({"email": email, "password": password})
                    if getattr(res, "user", None):
                        st.session_state.user = {"email": email, "id": res.user.id}
                        st.rerun()
                    else:
                        st.error("–ù–µ–≤–µ—Ä–Ω—ã–π email –∏–ª–∏ –ø–∞—Ä–æ–ª—å.")
            except Exception as e:
                msg = str(e)
                if "user_already_exists" in msg:
                    st.warning("‚ö†Ô∏è –¢–∞–∫–æ–π email —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω. –í–æ–π–¥–∏—Ç–µ.")
                elif "invalid_credentials" in msg:
                    st.error("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π email –∏–ª–∏ –ø–∞—Ä–æ–ª—å.")
                else:
                    st.error(f"–û—à–∏–±–∫–∞: {msg}")

# =========================
# üß† –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò
# =========================
def perplexity_generate(prompt: str) -> str:
    headers = {"Authorization": f"Bearer {PPLX_API_KEY}", "Content-Type": "application/json"}
    payload = {
        "model": "sonar-pro",
        "messages": [{"role": "user", "content": [{"type": "text", "text": prompt}]}],
        "max_output_tokens": 2000
    }
    r = requests.post("https://api.perplexity.ai/chat/completions", json=payload, headers=headers, timeout=90)
    if not r.ok:
        st.error(f"Perplexity API –æ—à–∏–±–∫–∞ {r.status_code}: {r.text}")
        r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]

def build_prompt(topic, site, competitors, lsi, banned, keys, symbols) -> str:
    return f"""
–¢—ã –æ–ø—ã—Ç–Ω—ã–π SEO-–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä –∏ –∂—É—Ä–Ω–∞–ª–∏—Å—Ç.
–ù–∞–ø–∏—à–∏ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π SEO-—Ç–µ–∫—Å—Ç –Ω–∞ —Ç–µ–º—É: {topic}
–°–∞–π—Ç –∫–ª–∏–µ–Ω—Ç–∞: {site}
–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã: {competitors}
–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keys}
LSI-—Ñ—Ä–∞–∑—ã (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ —É—á–µ—Å—Ç—å): {lsi}
–ó–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞: {banned}
–û–±—ä—ë–º ‚âà {symbols} —Å–∏–º–≤–æ–ª–æ–≤.
–ü–∏—à–∏ –∂–∏–≤—ã–º —è–∑—ã–∫–æ–º, –±–µ–∑ –∫–ª–∏—à–µ –∏ ‚Äú–ò–ò-—Ç–æ–Ω–∞‚Äù. –î–æ–±–∞–≤–ª—è–π –º–∏–∫—Ä–æ-–ø—Ä–∏–º–µ—Ä—ã, –¥–µ—Ç–∞–ª–∏ –∏ —Ñ–∞–∫—Ç—É—Ä—É.
"""

def clean_text(text: str) -> str:
    return re.sub(r"[#*_>`]+", "", text).strip()

def check_missing_lsi(text: str, lsi_list: list[str]) -> list[str]:
    low = text.lower()
    return [w for w in lsi_list if w and w.lower() not in low]

def seo_score(text: str, keywords: str) -> dict:
    words = re.findall(r"\w+", text.lower())
    word_count = len(words) or 1
    avg_len = sum(len(w) for w in words) / word_count
    key_density = sum(text.lower().count(k.strip().lower())
                      for k in keywords.split(",") if k.strip()) / word_count * 100
    sentences = [s for s in re.split(r"[.!?]", text) if s.strip()]
    avg_sentence_len = (sum(len(s.split()) for s in sentences) / len(sentences)) if sentences else 0
    water = len(re.findall(r"\b(–æ—á–µ–Ω—å|—ç—Ç–æ|—Ç–∞–∫–∂–µ|–ø–æ—ç—Ç–æ–º—É|–Ω–∞–ø—Ä–∏–º–µ—Ä|–≤ —Ü–µ–ª–æ–º|—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ)\b", text.lower())) / word_count * 100
    return {
        "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤": word_count,
        "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞": round(avg_len, 2),
        "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è": round(avg_sentence_len, 2),
        "–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –∫–ª—é—á–µ–π (%)": round(key_density, 2),
        "–í–æ–¥–Ω–æ—Å—Ç—å (%)": round(water, 2),
    }

def analyze_humanness(text: str) -> dict:
    sentences = [s.strip() for s in re.split(r"[.!?]", text) if s.strip()]
    words = re.findall(r"\w+", text.lower())
    unique_words = len(set(words)) or 1
    perplexity = round(np.exp(len(words) / unique_words), 2)
    lens = [len(s.split()) for s in sentences] or [0]
    burstiness = round(np.std(lens) / (np.mean(lens) + 1e-5), 2)
    bigrams = [f"{words[i]} {words[i+1]}" for i in range(max(0, len(words)-1))]
    repeats = len(bigrams) - len(set(bigrams))
    repeat_ratio = round(repeats / (len(bigrams) or 1) * 100, 2)
    human_score = 100 - ((perplexity / 50) * 20 + (repeat_ratio / 2) - (burstiness * 10))
    human_score = max(0, min(100, round(human_score, 1)))
    return {
        "–ü–µ—Ä–ø–ª–µ–∫—Å–∏—è": perplexity,
        "–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π": burstiness,
        "–ü–æ–≤—Ç–æ—Ä—è–µ–º–æ—Å—Ç—å —Ñ—Ä–∞–∑ (%)": repeat_ratio,
        "–ï—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞ (%)": human_score,
    }

def export_docx(text: str, report: dict, human_report: dict, filename="seo_text.docx"):
    doc = Document()
    doc.add_heading("SEO Rezult Text Master ‚Äî –û—Ç—á—ë—Ç", level=1)
    doc.add_paragraph(text)
    doc.add_page_break()
    doc.add_heading("üìä SEO-–∞–Ω–∞–ª–∏–∑", level=2)
    for k, v in report.items():
        doc.add_paragraph(f"{k}: {v}")
    doc.add_heading("üß† –ê–Ω–∞–ª–∏–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏", level=2)
    for k, v in human_report.items():
        doc.add_paragraph(f"{k}: {v}")
    doc.save(filename)
    with open(filename, "rb") as f:
        st.download_button("üì• –°–∫–∞—á–∞—Ç—å DOCX-–æ—Ç—á—ë—Ç", f, file_name=filename)

# =========================
# üß≠ –û–°–ù–û–í–ù–û–ô UI
# =========================
if not st.session_state.user:
    st.info("üîë –í–æ–π–¥–∏—Ç–µ –∏–ª–∏ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä.")
    st.stop()

email = st.session_state.user["email"]
is_admin = (email.lower() == "admin@seo-rezult.ru")

st.title("üöÄ SEO Rezult Text Master v7.4")
st.caption("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä SEO-—Ç–µ–∫—Å—Ç–æ–≤ —Å LSI-–∏—Ç–µ—Ä–∞—Ü–∏—è–º–∏, –ø—Ä–æ–≤–µ—Ä–∫–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏")

tab_labels = ["üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è", "üìÇ –ú–æ–∏ —Ç–µ–∫—Å—Ç—ã"]
if is_admin:
    tab_labels.append("üßë‚Äçüíº –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å")
tabs = st.tabs(tab_labels)

# -------------------------
# üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
# -------------------------
with tabs[0]:
    with st.form("input_form"):
        topic = st.text_input("–¢–µ–º–∞—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞")
        site = st.text_input("–°–∞–π—Ç –∫–ª–∏–µ–Ω—Ç–∞")
        competitors = st.text_area("–°—Å—ã–ª–∫–∏ –Ω–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–ø–æ –æ–¥–Ω–æ–π –≤ —Å—Ç—Ä–æ–∫–µ)")
        lsi_words = st.text_area("–°–ø–∏—Å–æ–∫ LSI-—Å–ª–æ–≤ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)")
        banned = st.text_area("–ó–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)")
        keywords = st.text_area("–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)")
        symbols = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤", value=8000, step=500)
        submitted = st.form_submit_button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç")

    if submitted:
        lsi_list = [w.strip() for w in lsi_words.split(",") if w.strip()]
        st.info("‚öôÔ∏è –≠—Ç–∞–ø 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞...")
        base = build_prompt(topic, site, competitors, lsi_words, banned, keywords, symbols)
        text = clean_text(perplexity_generate(base))

        iteration = 1
        progress = st.progress(0)
        while True:
            missing = check_missing_lsi(text, lsi_list)
            if not missing:
                break
            st.warning(f"–≠—Ç–∞–ø 2: –¥–æ–±–∞–≤–ª—è–µ–º {len(missing)} LSI-—Å–ª–æ–≤(–∞)...")
            fix_prompt = (
                f"–î–æ–±–∞–≤—å –≤ —Ç–µ–∫—Å—Ç —Å–ª–æ–≤–∞ {', '.join(missing)}.\n"
                f"–ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç:\n{text}"
            )
            addition = clean_text(perplexity_generate(fix_prompt))
            text += "\n" + addition
            iteration += 1
            progress.progress(min(90, iteration * 20))
        progress.progress(100)

        st.success("‚úÖ –¢–µ–∫—Å—Ç –≥–æ—Ç–æ–≤!")
        st.text_area("–†–µ–∑—É–ª—å—Ç–∞—Ç", text, height=400)

        st.info("üîé –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ (Text.ru)‚Ä¶")
        try:
            r = requests.post("https://api.text.ru/post", data={"text": text, "userkey": TEXT_RU_KEY}, timeout=30)
            if r.ok and "text_uid" in r.json():
                uid = r.json()["text_uid"]
                res = requests.get("https://api.text.ru/post", params={"uid": uid, "userkey": TEXT_RU_KEY}, timeout=30).json()
                uniq = res.get("text_unique", "?")
                st.write(f"**–£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å:** {uniq}%")
        except Exception as e:
            st.warning(f"Text.ru –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {e}")

        st.info("üìä SEO-–∞–Ω–∞–ª–∏–∑")
        report = seo_score(text, keywords)
        st.table(report.items())

        st.info("üß† –ê–Ω–∞–ª–∏–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏")
        human_report = analyze_humanness(text)
        st.table(human_report.items())

        export_docx(text, report, human_report)

        try:
            supabase.table("history").insert({
                "user_id": st.session_state.user["id"],
                "email": email,
                "date": datetime.now().isoformat(),
                "topic": topic,
                "symbols": int(symbols),
                "lsi_count": len(lsi_list),
                "text": text
            }).execute()
        except Exception as e:
            st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é: {e}")

        st.markdown(f"[üß© –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ AI Detector](https://aidetectorwriter.com/ru/?text={quote(text)})")

# -------------------------
# üìÇ –ú–æ–∏ —Ç–µ–∫—Å—Ç—ã
# -------------------------
with tabs[1]:
    st.subheader("üìÇ –ú–æ–∏ —Ç–µ–∫—Å—Ç—ã")
    try:
        data = supabase.table("history").select("*").eq("user_id", st.session_state.user["id"]).order("date", desc=True).execute()
        rows = data.data or []
        if not rows:
            st.info("–ü–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.")
        for row in rows:
            with st.expander(f"{row.get('topic','‚Äî')} ‚Äî {row.get('date','')}"):
                st.write(row.get("text","")[:600] + "‚Ä¶")
                st.caption(f"–°–∏–º–≤–æ–ª–æ–≤: {row.get('symbols','?')}, LSI: {row.get('lsi_count','?')}")
                if st.button(f"üóë –£–¥–∞–ª–∏—Ç—å", key=f"del_{row['id']}"):
                    supabase.table("history").delete().eq("id", row["id"]).execute()
                    st.rerun()
    except Exception as e:
        st.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏—Å—Ç–æ—Ä–∏–∏: {e}")

# -------------------------
# üßë‚Äçüíº –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å
# -------------------------
if is_admin and len(tabs) > 2:
    with tabs[2]:
        st.subheader("üßë‚Äçüíº –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å (–≤—Å–µ —Ç–µ–∫—Å—Ç—ã)")
        try:
            data = supabase.table("history").select("*").order("date", desc=True).execute()
            rows = data.data or []
            if not rows:
                st.info("–ë–∞–∑–∞ –ø—É—Å—Ç–∞.")
            for row in rows:
                with st.expander(f"{row.get('email','?')} ‚Äî {row.get('topic','‚Äî')} ‚Äî {row.get('date','')}"):
                    st.write(row.get("text","")[:600] + "‚Ä¶")
                    st.caption(f"–°–∏–º–≤–æ–ª–æ–≤: {row.get('symbols','?')}, LSI: {row.get('lsi_count','?')}")
                    if st.button(f"üóë –£–¥–∞–ª–∏—Ç—å {row['id']}", key=f"adm_del_{row['id']}"):
                        supabase.table("history").delete().eq("id", row["id"]).execute()
                        st.rerun()
        except Exception as e:
            st.warning(f"–û—à–∏–±–∫–∞ –∞–¥–º–∏–Ω-–ø–∞–Ω–µ–ª–∏: {e}")

# =========================
# üöÄ Keep Alive
# =========================
keep_alive()
