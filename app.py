import streamlit as st
import requests, re, os, numpy as np
from datetime import datetime
from docx import Document
from urllib.parse import quote
from supabase import create_client, Client
from dotenv import load_dotenv

# =========================
# ‚öôÔ∏è –ù–ê–°–¢–†–û–ô–ö–ê –ü–û–î–ö–õ–Æ–ß–ï–ù–ò–ô
# =========================
load_dotenv()
PPLX_API_KEY = os.getenv("PPLX_API_KEY") or st.secrets.get("PPLX_API_KEY")
TEXT_RU_KEY = os.getenv("TEXT_RU_KEY") or st.secrets.get("TEXT_RU_KEY")
SUPABASE_URL = st.secrets["SUPABASE_URL"]
SUPABASE_KEY = st.secrets["SUPABASE_KEY"]
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

st.set_page_config(page_title="SEO Rezult Text Master v7.3", layout="wide")

# =========================
# üîê –ê–í–¢–û–†–ò–ó–ê–¶–ò–Ø
# =========================
if "user" not in st.session_state:
    st.session_state.user = None

with st.sidebar:
    st.header("üîê –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è")

    if st.session_state.user:
        st.success(f"–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å, {st.session_state.user['email']}!")
        if st.button("–í—ã–π—Ç–∏"):
            st.session_state.user = None
            st.rerun()
    else:
        mode = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ:", ["–í—Ö–æ–¥", "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è"])
        email = st.text_input("Email")
        password = st.text_input("–ü–∞—Ä–æ–ª—å", type="password")

        if st.button("–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å"):
            try:
                # --- –†–ï–ì–ò–°–¢–†–ê–¶–ò–Ø ---
                if mode == "–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è":
                    # üõ°Ô∏è –ó–∞–ø—Ä–µ—â–∞–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—é –ø–æ–¥ –∞–¥–º–∏–Ω—Å–∫–∏–º email
                    if email.lower().strip() == "admin@seo-rezult.ru":
                        st.error("–†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–¥ —ç—Ç–∏–º –∞–¥—Ä–µ—Å–æ–º –∑–∞–ø—Ä–µ—â–µ–Ω–∞. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
                    else:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º ‚Äî –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ç–∞–∫–æ–π email
                        existing_user = supabase.table("auth.users").select("email").eq("email", email).execute()
                        if existing_user.data:
                            st.warning("‚ö†Ô∏è –¢–∞–∫–æ–π email —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ–π—Ç–∏.")
                        else:
                            res = supabase.auth.sign_up({"email": email, "password": password})
                            if res.user:
                                st.success("‚úÖ –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ø—Ä–æ—à–ª–∞ —É—Å–ø–µ—à–Ω–æ! –¢–µ–ø–µ—Ä—å –≤–æ–π–¥–∏—Ç–µ.")
                            else:
                                st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.")
                # --- –í–•–û–î ---
                else:
                    res = supabase.auth.sign_in_with_password({"email": email, "password": password})
                    if res.user:
                        st.session_state.user = {"email": email, "id": res.user.id}
                        st.rerun()
                    else:
                        st.error("–ù–µ–≤–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –≤—Ö–æ–¥–∞.")
            except Exception as e:
                msg = str(e)
                if "user_already_exists" in msg:
                    st.warning("‚ö†Ô∏è –¢–∞–∫–æ–π email —É–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≤–æ–π—Ç–∏.")
                elif "invalid_credentials" in msg:
                    st.error("‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π email –∏–ª–∏ –ø–∞—Ä–æ–ª—å.")
                else:
                    st.error(f"–û—à–∏–±–∫–∞: {msg}")

# =========================
# üß† –û–°–ù–û–í–ù–û–ô –ò–ù–¢–ï–†–§–ï–ô–°
# =========================
if st.session_state.user:
    email = st.session_state.user["email"]
    is_admin = email == "admin@seo-rezult.ru"

    st.title("üöÄ SEO Rezult Text Master")
    st.caption("–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä SEO-—Ç–µ–∫—Å—Ç–æ–≤ —Å LSI-–∞–Ω–∞–ª–∏–∑–æ–º, –ø—Ä–æ–≤–µ—Ä–∫–æ–π —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏")

    tab_labels = ["üìù –ì–µ–Ω–µ—Ä–∞—Ü–∏—è", "üìÇ –ú–æ–∏ —Ç–µ–∫—Å—Ç—ã"]
    if is_admin:
        tab_labels.append("üßë‚Äçüíº –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å")

    tabs = st.tabs(tab_labels)

    # -----------------------------------------------------
    # –í–∫–ª–∞–¥–∫–∞ 1 ‚Äî –ì–µ–Ω–µ—Ä–∞—Ü–∏—è
    # -----------------------------------------------------
    with tabs[0]:
        with st.form("input_form"):
            topic = st.text_input("–¢–µ–º–∞—Ç–∏–∫–∞ —Ç–µ–∫—Å—Ç–∞")
            site = st.text_input("–°–∞–π—Ç –∫–ª–∏–µ–Ω—Ç–∞")
            competitors = st.text_area("–°—Å—ã–ª–∫–∏ –Ω–∞ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ (–ø–æ –æ–¥–Ω–æ–π –≤ —Å—Ç—Ä–æ–∫–µ)")
            lsi_words = st.text_area("–°–ø–∏—Å–æ–∫ LSI-—Å–ª–æ–≤ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)")
            banned = st.text_area("–ó–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)")
            keywords = st.text_area("–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ (—á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é)")
            symbols = st.number_input("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–∏–º–≤–æ–ª–æ–≤", value=8000, step=500)
            submitted = st.form_submit_button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç")

        def perplexity_generate(prompt: str):
            headers = {"Authorization": f"Bearer {PPLX_API_KEY}", "Content-Type": "application/json"}
            payload = {
                "model": "sonar-pro",
                "messages": [{"role": "user", "content": [{"type": "text", "text": prompt}]}],
                "max_output_tokens": 2000
            }
            r = requests.post("https://api.perplexity.ai/chat/completions", json=payload, headers=headers)
            if not r.ok:
                st.error(f"Perplexity API –≤–µ—Ä–Ω—É–ª –æ—à–∏–±–∫—É {r.status_code}: {r.text}")
                r.raise_for_status()
            return r.json()["choices"][0]["message"]["content"]

        def build_prompt(topic, site, competitors, lsi, banned, keys, symbols):
            return f"""
–¢—ã –æ–ø—ã—Ç–Ω—ã–π SEO-–∫–æ–ø–∏—Ä–∞–π—Ç–µ—Ä.
–ù–∞–ø–∏—à–∏ —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π SEO-—Ç–µ–∫—Å—Ç –Ω–∞ —Ç–µ–º—É: {topic}.
–°–∞–π—Ç –∫–ª–∏–µ–Ω—Ç–∞: {site}.
–ö–æ–Ω–∫—É—Ä–µ–Ω—Ç—ã: {competitors}.
–ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {keys}.
LSI-—Ñ—Ä–∞–∑—ã: {lsi}.
–ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–≤–∞: {banned}.
–û–±—ä—ë–º ‚âà {symbols} —Å–∏–º–≤–æ–ª–æ–≤.
–ü–∏—à–∏ –∂–∏–≤—ã–º —è–∑—ã–∫–æ–º, –±–µ–∑ —à–∞–±–ª–æ–Ω–æ–≤ –∏ ‚Äú–ò–ò-—Ç–æ–Ω–∞‚Äù.
"""

        def clean_text(text):
            return re.sub(r"[#*_>`]+", "", text).strip()

        def check_missing_lsi(text, lsi_list):
            return [w for w in lsi_list if w.lower() not in text.lower()]

        def seo_score(text, keywords):
            words = re.findall(r"\w+", text.lower())
            word_count = len(words)
            avg_len = sum(len(w) for w in words) / len(words)
            key_density = sum(text.lower().count(k.lower()) for k in keywords.split(",")) / max(word_count, 1) * 100
            sentences = re.split(r"[.!?]", text)
            avg_sentence_len = sum(len(s.split()) for s in sentences if s.strip()) / max(len(sentences), 1)
            water = len(re.findall(r"\b(–æ—á–µ–Ω—å|—ç—Ç–æ|—Ç–∞–∫–∂–µ|–ø–æ—ç—Ç–æ–º—É|–Ω–∞–ø—Ä–∏–º–µ—Ä|–≤ —Ü–µ–ª–æ–º|—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ)\b", text.lower())) / max(word_count, 1) * 100
            return {
                "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤": word_count,
                "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ —Å–ª–æ–≤–∞": round(avg_len, 2),
                "–°—Ä–µ–¥–Ω—è—è –¥–ª–∏–Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è": round(avg_sentence_len, 2),
                "–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –∫–ª—é—á–µ–π (%)": round(key_density, 2),
                "–í–æ–¥–Ω–æ—Å—Ç—å (%)": round(water, 2)
            }

        def analyze_humanness(text):
            sentences = [s.strip() for s in re.split(r'[.!?]', text) if s.strip()]
            words = re.findall(r'\w+', text.lower())
            unique_words = len(set(words))
            perplexity = round(np.exp(len(words) / max(unique_words, 1)), 2)
            sentence_lengths = [len(s.split()) for s in sentences]
            burstiness = round(np.std(sentence_lengths) / (np.mean(sentence_lengths) + 1e-5), 2)
            bigrams = [f"{words[i]} {words[i+1]}" for i in range(len(words)-1)]
            repeats = len(bigrams) - len(set(bigrams))
            repeat_ratio = round(repeats / max(len(bigrams), 1) * 100, 2)
            human_score = 100 - ((perplexity / 50) * 20 + (repeat_ratio / 2) - (burstiness * 10))
            human_score = max(0, min(100, round(human_score, 1)))
            return {
                "–ü–µ—Ä–ø–ª–µ–∫—Å–∏—è (–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç—å)": perplexity,
                "–†–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (Burstiness)": burstiness,
                "–ü–æ–≤—Ç–æ—Ä—è–µ–º–æ—Å—Ç—å —Ñ—Ä–∞–∑ (%)": repeat_ratio,
                "–û—Ü–µ–Ω–∫–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ (%)": human_score
            }

        def export_docx(text, report, human_report, filename="seo_text.docx"):
            doc = Document()
            doc.add_heading("SEO Rezult Text Master ‚Äî –û—Ç—á—ë—Ç", level=1)
            doc.add_paragraph(text)
            doc.add_page_break()
            doc.add_heading("üìä SEO-–∞–Ω–∞–ª–∏–∑", level=2)
            for k, v in report.items():
                doc.add_paragraph(f"{k}: {v}")
            doc.add_heading("üß† –ê–Ω–∞–ª–∏–∑ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏", level=2)
            for k, v in human_report.items():
                doc.add_paragraph(f"{k}: {v}")
            doc.save(filename)
            with open(filename, "rb") as f:
                st.download_button("üì• –°–∫–∞—á–∞—Ç—å DOCX-–æ—Ç—á—ë—Ç", f, file_name=filename)

        if submitted:
            st.info("‚öôÔ∏è –≠—Ç–∞–ø 1: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ Perplexity...")
            lsi_list = [w.strip() for w in lsi_words.split(",") if w.strip()]
            text = perplexity_generate(build_prompt(topic, site, competitors, lsi_words, banned, keywords, symbols))
            text = clean_text(text)
            iteration = 1
            progress = st.progress(0)
            while True:
                missing = check_missing_lsi(text, lsi_list)
                if not missing:
                    break
                st.warning(f"–≠—Ç–∞–ø 2: –¥–æ—Ä–∞–±–æ—Ç–∫–∞ LSI ({len(missing)} —Å–ª–æ–≤)...")
                addition = perplexity_generate(f"–î–æ–±–∞–≤—å –∞–±–∑–∞—Ü —Å–æ —Å–ª–æ–≤–∞–º–∏: {', '.join(missing)}.\n\n{text}")
                text += "\n" + clean_text(addition)
                iteration += 1
                progress.progress(min(90, iteration * 20))
            progress.progress(100)
            st.success("‚úÖ –¢–µ–∫—Å—Ç –≥–æ—Ç–æ–≤!")
            st.text_area("–†–µ–∑—É–ª—å—Ç–∞—Ç", text, height=400)

            # === –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ ===
            st.info("üîé –ü—Ä–æ–≤–µ—Ä–∫–∞ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ —á–µ—Ä–µ–∑ Text.ru API...")
            r = requests.post("https://api.text.ru/post", data={"text": text, "userkey": TEXT_RU_KEY})
            if r.ok:
                res = requests.get("https://api.text.ru/post", params={"uid": r.json()["text_uid"], "userkey": TEXT_RU_KEY}).json()
                uniq = res.get("text_unique", "?")
                st.write(f"**–£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å:** {uniq}%")
            else:
                st.warning("–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏.")

            report = seo_score(text, keywords)
            st.table(report.items())

            human_report = analyze_humanness(text)
            st.table(human_report.items())

            export_docx(text, report, human_report)
            supabase.table("history").insert({
                "user_id": st.session_state.user["id"],
                "email": st.session_state.user["email"],
                "date": datetime.now().isoformat(),
                "topic": topic,
                "symbols": symbols,
                "lsi_count": len(lsi_list),
                "text": text
            }).execute()

    # -----------------------------------------------------
    # –í–∫–ª–∞–¥–∫–∞ 2 ‚Äî –ú–æ–∏ —Ç–µ–∫—Å—Ç—ã
    # -----------------------------------------------------
    with tabs[1]:
        st.subheader("üìÇ –ú–æ–∏ —Ç–µ–∫—Å—Ç—ã")
        user_id = st.session_state.user["id"]
        data = supabase.table("history").select("*").eq("user_id", user_id).order("date", desc=True).execute()
        if data.data:
            for row in data.data:
                with st.expander(f"{row['topic']} ‚Äî {row['date']}"):
                    st.write(row["text"][:400] + "...")
                    if st.button("üóë –£–¥–∞–ª–∏—Ç—å", key=row["id"]):
                        supabase.table("history").delete().eq("id", row["id"]).execute()
                        st.rerun()
        else:
            st.info("–ü–æ–∫–∞ –Ω–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤.")

    # -----------------------------------------------------
    # –í–∫–ª–∞–¥–∫–∞ 3 ‚Äî –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å
    # -----------------------------------------------------
    if is_admin:
        with tabs[2]:
            st.subheader("üßë‚Äçüíº –ê–¥–º–∏–Ω-–ø–∞–Ω–µ–ª—å: –≤—Å–µ —Ç–µ–∫—Å—Ç—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π")
            data = supabase.table("history").select("*").order("date", desc=True).execute()
            if data.data:
                for row in data.data:
                    with st.expander(f"{row['email']} ‚Äî {row['topic']} ‚Äî {row['date']}"):
                        st.write(row["text"][:400] + "...")
                        if st.button(f"üóë –£–¥–∞–ª–∏—Ç—å {row['id']}", key=f"adm_{row['id']}"):
                            supabase.table("history").delete().eq("id", row["id"]).execute()
                            st.rerun()
            else:
                st.info("–ë–∞–∑–∞ –ø—É—Å—Ç–∞.")
else:
    st.info("üîë –í–æ–π–¥–∏—Ç–µ –∏–ª–∏ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–π—Ç–µ—Å—å, —á—Ç–æ–±—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä.")
